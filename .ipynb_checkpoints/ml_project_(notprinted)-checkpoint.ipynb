{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a280595e",
   "metadata": {},
   "source": [
    "# Prediction of travel products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082880d5",
   "metadata": {},
   "source": [
    "## 1. 프로젝트 주제 : 여행 패키지 상품 신청 예측 프로젝트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c16ffd6",
   "metadata": {},
   "source": [
    "* 해결하고자 하는 문제 : 어떤 특성에 따라 고객이 여행 패키지상품을 고객이 신청할 지 여부를 예측하여 회사의 광고비를 줄이고, 매출을 극대화하는 방향을 모색하고자 한다.    \n",
    "* 데이터 \n",
    "    * 데이콘의 데이터 (train : 1955개의 데이터)\n",
    "    * 선정이유 : 코로나시국 이후로 관광을 많이 못한 사람들의 여행수요가 증가하고 있다. 많은 수요자 중 어떤 고객의 특성이 여행상품을 선택할 지 예측해보고자 한다.   \n",
    "    * 사용할 Target 특성은 ProdTaken(여행 패키지 신청 여부)로, binary 분류문제이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739df540",
   "metadata": {},
   "source": [
    "## 2. Import Library and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b8a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from category_encoders import OneHotEncoder,OrdinalEncoder\n",
    "\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from pdpbox.pdp import pdp_isolate, pdp_plot\n",
    "\n",
    "import shap\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer # 결측치를 평균으로 대체\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, plot_confusion_matrix, accuracy_score, f1_score,roc_curve, roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a624f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('data/train.csv')\n",
    "df = raw_data.copy()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06b04f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id만 없는 raw_data저장\n",
    "raw_data = raw_data.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64469dfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f08df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # 1955*20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bbf9fd",
   "metadata": {},
   "source": [
    "### 특성 설명(데이콘)\n",
    "\n",
    "id : 샘플 아이디  \n",
    "Age : 나이  \n",
    "TypeofContact : 고객의 제품 인지 방법 (회사의 홍보 or 스스로 검색)  \n",
    "CityTier : 주거 중인 도시의 등급. (인구, 시설, 생활 수준 기준) (1등급 > 2등급 > 3등급)  \n",
    "DurationOfPitch : 영업 사원이 고객에게 제공하는 프레젠테이션 기간  \n",
    "Occupation : 직업  \n",
    "Gender : 성별  \n",
    "NumberOfPersonVisiting : 고객과 함께 여행을 계획 중인 총 인원  \n",
    "NumberOfFollowups : 영업 사원의 프레젠테이션 후 이루어진 후속 조치 수  \n",
    "ProductPitched : 영업 사원이 제시한 상품  \n",
    "PreferredPropertyStar : 선호 호텔 숙박업소 등급  \n",
    "MaritalStatus : 결혼여부  \n",
    "NumberOfTrips : 평균 연간 여행 횟수  \n",
    "Passport : 여권 보유 여부 (0: 없음, 1: 있음)  \n",
    "PitchSatisfactionScore : 영업 사원의 프레젠테이션 만족도  \n",
    "OwnCar : 자동차 보유 여부 (0: 없음, 1: 있음)  \n",
    "NumberOfChildrenVisiting : 함께 여행을 계획 중인 5세 미만의 어린이 수  \n",
    "Designation : (직업의) 직급  \n",
    "MonthlyIncome : 월 급여  \n",
    "ProdTaken : 여행 패키지 신청 여부 (0: 신청 안 함, 1: 신청함)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ac545a",
   "metadata": {},
   "source": [
    "## 3. 데이터를 이용한 가설, 기준모델(Baseline Model), 평가지표설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacfb620",
   "metadata": {},
   "source": [
    "* 가설(탐색적데이터분석)  \n",
    "    * 가설1 : 결혼 후, 여행을 계획중인 아이들이 있으면 가족패키지에 대한 수요가 있어 패키지신청확률이 높을 것이다.  \n",
    "    * 가설2 : 영업 사원의 프레젠테이션 만족도는 가족패키지에 대한 수요와 연관성이 높을 것이다.  \n",
    "      \n",
    "    \n",
    "* 기준모델 및 평가지표설명\n",
    "    * Baseline Model은 초기 최빈값인 0.79에서 Logistic Regression의 AUC Score로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6630ab77",
   "metadata": {},
   "source": [
    "## 4. EDA & Datapreprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9799c25",
   "metadata": {},
   "source": [
    "    * Gender 컬럼의 'Fe Male'->'Female'로 수정  \n",
    "    * 결측치제거  \n",
    "    * unique 컬럼 제거(id)\n",
    "    * age특성 age로 구간설정\n",
    "    * DurationOfPitch을 구간별로 설정\n",
    "    * Monthly Income을 구간별로 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031a24d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 결측치확인\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c865df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df_):\n",
    "    \n",
    "    # Gender 특성 데이터정리\n",
    "    df_['Gender'] = df_['Gender'].str.replace('Fe Male', 'Female')\n",
    "    \n",
    "    df_ = df_.dropna()\n",
    "    \n",
    "    # 나이를 기준으로 나이대별 컬럼생성\n",
    "    df_['Ages'] = (df_['Age']//10*10).astype(int)\n",
    "    # Age컬럼 삭제하기(시각화 후 모델링 직전에 삭제.)\n",
    "    \n",
    "    df_['DurationOfPitchSection'] = pd.cut(df_['DurationOfPitch'], \n",
    "                                        bins = [0,5,10, 15, 20,25,30,35,40], \n",
    "                                        labels = ['~5', '~10', '~15', '~20','~25','~30','~35','~40'])\n",
    "\n",
    "    \n",
    "    df_['MonthlyIncomeSection'] = pd.cut(df_['MonthlyIncome'], \n",
    "                                        bins = [0,15000,20000, 25000, 30000,35000,40000,45000,50000,100000], \n",
    "                                        labels = ['~15000', '~20000', '~25000', '~30000','~35000','~40000','~45000','~50000','~100000'])\n",
    "\n",
    "    # high cardinality로 불필요한 컬럼 삭제\n",
    "    # df = df.drop(['id'],axis=1)\n",
    "    \n",
    "    return df_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a59625e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트데이터도 추후 전처리 해줘야함!!!! 모델링하는거 봐서 더 잘 먹는걸로 전처리하기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "055fe503",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 컬럼별 데이터내용 확인\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# 컬럼별 데이터내용 확인\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b31ab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 컬럼별 데이터 내용 확인\n",
    "for i in df.columns:\n",
    "    print(df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc4c8ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data_preprocessing(df).reset_index(drop=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab998acf",
   "metadata": {},
   "source": [
    "## 5. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633e723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성별 상관관계 히트맵으로 표현.\n",
    "\n",
    "# seaborn setting\n",
    "rcParams['figure.figsize'] = 15,8\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "plt.rcParams['font.size'] = 15\n",
    "colors = sns.color_palette('pastel')\n",
    "\n",
    "sns.heatmap(data=raw_data.corr(), annot=True, fmt='.2f', linewidths=.5, cmap='Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb458f0",
   "metadata": {},
   "source": [
    "* 특성간 상관관계가 높을수록 진한색을 띄는데, 데이터를 확인시, 특성간 뚜렷한 상관관계가 보이지 않음을 확인하였다.   \n",
    "\n",
    "\n",
    "* 타겟인 ProdTaken와 상관관계가 가장 높은 것은 여권소지유무로 0.32가 가장 높은 값이다.  \n",
    "* 함께 여행을 계획 중인 5세 미만의 어린이 수 고객과 함께 여행을 계획 중인 총 인원은 0.6의 상관관계로 상관관계수치 중 가장 높은 값을 보인다.  \n",
    "\n",
    "\n",
    "* 타겟의 상관관계가 음수로 나타난 경우  \n",
    "    * 나이와 타겟의 상관관계 : 이는 고령일수록 패키지여행신청을 하지 않음을 보여준다.  \n",
    "    * 차량과 타겟의 상관관계 : 차가 없는 경우가 패키지여행을 더 고려하는 것을 보여준다.\n",
    "    * 월별소득과 타겟의 상관관계 : 소득이 적을 때 패키지여행을 더 고려하는 것을 보여준다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd9fd1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 연관분석\n",
    "from matplotlib import rc\n",
    "rc('axes', unicode_minus=False)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "heatmap = sns.heatmap(data.corr()[['ProdTaken']].sort_values(by='ProdTaken', ascending=False), vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "heatmap.set_title('Features Correlating with ProdTaken', fontdict={'fontsize':18}, pad=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3404da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수는 주성분분석불가, 데이터를 수치형 데이터로 변경 후, 카테고리로 데이터타입을 변경하여 주성분분석에 사용\n",
    "# 주성분분석을 통해 전체 열 중에 중요 열을 추리는 것이 목적EDA로 구간별로 구분한 컬럼을 카테고리화하기\n",
    "\n",
    "category_data = data.drop(['MonthlyIncome','Age','DurationOfPitch'],axis=1)\n",
    "category_data\n",
    "\n",
    "category_data_fac = category_data.apply(lambda x: pd.factorize(x)[0])\n",
    "category_data_fac = category_data.astype('category')\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "category_data_fac_encoded = encoder.fit_transform(category_data_fac)\n",
    "\n",
    "category_data_fac_encoded_catego = category_data_fac_encoded.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf83069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 주성분분석을 통해 특정 컬럼이 주성분분석결과를 설명할 수 있다고 보여지지 않음\n",
    "\n",
    "from psynlig import pca_explained_variance_pie\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "rcParams['figure.figsize'] = 15,8\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "plt.rcParams['font.size'] = 15\n",
    "colors = sns.color_palette('pastel')\n",
    "\n",
    "data_for_pca = scale(category_data_fac_encoded_catego)\n",
    "\n",
    "pca = PCA(n_components=16) # \n",
    "pca.fit_transform(data_for_pca)\n",
    "\n",
    "fig, axi = pca_explained_variance_pie(pca, cmap='Spectral')\n",
    "axi.set_title('Explained variance by principal components',fontsize=30)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc79b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 구성비율확인\n",
    "print(data['ProdTaken'].value_counts())\n",
    "\n",
    "print(data['ProdTaken'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5680a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟의 imbalance 확인\n",
    "%matplotlib inline\n",
    "\n",
    "sns.countplot(x=data['ProdTaken']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051fc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProdTaken이 1로 나온 특성별 분포확인(여행패키지 신청한 경우)\n",
    "\n",
    "dataa = data[data['ProdTaken']==1]\n",
    "dataa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0e76c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d984d8c4",
   "metadata": {},
   "source": [
    "### 데이터 분포확인1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed97e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataa.columns:\n",
    "    sns.displot(x=dataa[i],kde=True) # kde : 커널밀도추정. 커널함수와 데이터를 바탕으로 연속성있는 확률밀도함수를 추정하는것."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5908e474",
   "metadata": {},
   "source": [
    "### 데이터 분포확인2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96468905",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,50))\n",
    "\n",
    "sns.set_theme(style=\"white\") \n",
    "cols=['TypeofContact', 'CityTier', 'DurationOfPitch', 'Occupation', 'Gender',\n",
    "       'NumberOfPersonVisiting', 'NumberOfFollowups', 'ProductPitched',\n",
    "       'PreferredPropertyStar', 'MaritalStatus', 'NumberOfTrips', 'Passport',\n",
    "       'PitchSatisfactionScore', 'OwnCar', 'NumberOfChildrenVisiting',\n",
    "       'Designation', 'ProdTaken', 'Ages', 'MonthlyIncomeSection']\n",
    "for i, variable in enumerate(cols):\n",
    "                     ax=plt.subplot(15,2,i+1)\n",
    "                     #order = data[variable].value_counts(ascending=False).index   \n",
    "                     #sns.set_palette(list_palette[i]) # to set the palette\n",
    "                     sns.set_palette('Set2')\n",
    "                    \n",
    "                     ax=sns.countplot(x=data[variable], data=data )\n",
    "                     sns.despine(top=True,right=True,left=True) # 그래프위,양옆선삭제\n",
    "                     for p in ax.patches:\n",
    "                           percentage = '{:.1f}%'.format(100 * p.get_height()/len(data[variable]))\n",
    "                           x = p.get_x() + p.get_width() / 2 - 0.05\n",
    "                           y = p.get_y() + p.get_height()\n",
    "                           plt.annotate(percentage, (x, y),ha='center') # 주석\n",
    "                     plt.tight_layout()\n",
    "                     #plt.title(cols[i].upper())\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d988a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DurationOfPitch'].value_counts(normalize=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad94c6f",
   "metadata": {},
   "source": [
    "### * 특성별 분포도 분석\n",
    "\n",
    "회사 제품의 인지방법(TypeofContact) : 고객 스스로 검색이 70%로 반 회사의 홍보(30%)보다 2배 많음  \n",
    "주거 중인 도시의 등급(CityTier)이 1등급이 가장 많은데, 생활수준이 가장 좋은 곳의 사람들을 대상으로 수집한 정보임을 알 수 있다.(1등급 > 2등급 > 3등급)  \n",
    "영업 사원이 고객에게 제공하는 프레젠테이션 기간(DurationOfPitch)은 17이상으로는 급격히 떨어짐을 확인할 수 있다.  \n",
    "조사된 사람들의 대부분의 직업(Occupation) 중 반은 직장인, 그리고 두번째는 작은사업을 하고 있다고 하는 경우가 많았고,  \n",
    "Designation을 보면 가장 높은 직급이 Executive, Manager인 것으로 보아 생활수준이 좋은 사람들의 데이터라볼 수 있다.  \n",
    "  \n",
    "성별(Gender)은 60%이상이 남자고,  \n",
    "고객과 함께 여행을 계획 중인 총 인원은 3명이 과반수를 넘었으며,   \n",
    "프레젠테이션 후 이루어진 후속 조치 수(NumberOfFollowups)는 4점이 44%로 가장 높았고,  \n",
    "영업 사원이 제시한 상품(ProductPitched)은 basic, delux순으로 많았으며,  \n",
    "선호 호텔 숙박업소 등급(PreferredPropertyStar)은 3점이 가장 많았고,  \n",
    "결혼여부(MaritalStatus)는 결혼한 경우가 많았다. (unmarried는 사실혼의 경우로 본다)  \n",
    "평균 연간 여행 횟수(NumberOfTrips)는 2번, 그 다음 3번이 가장 많았고,   \n",
    "여권 보유 여부(Passport)은 없는 경우가 70%를 넘었다.  \n",
    "영업 사원의 프레젠테이션 만족도(PitchSatisfactionScore)는 3점이 가장 높았으며,  \n",
    "자동차 보유 여부(OwnCar)는 있는 경우가 61%를 넘었다.  \n",
    "함께 여행을 계획 중인 5세 미만의 어린이 수(NumberOfChildrenVisiting)는 1명, 2명 순으로 많았다.  \n",
    "여행 패키지 신청 여부(ProdTaken)는 20%의 고객만이 진행됐고,  \n",
    "나이대(Ages)는 30대가 44%로 가장 높았으며,  \n",
    "월 급여구간(MonthlyIncomeSection)은 20000~25000이 가장 많았다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861279f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=data, x=\"ProdTaken\", y=\"MonthlyIncome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815136ee",
   "metadata": {},
   "source": [
    "### 데이터분포3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce291c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to plot distributions and Boxplots of customers\n",
    "rcParams['figure.figsize'] = 15,8\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "plt.rcParams['font.size'] = 15\n",
    "colors = sns.color_palette('pastel')\n",
    "\n",
    "def plot(x,target='ProdTaken'):\n",
    "    \n",
    "    fig,axs = plt.subplots(2,2,figsize=(12,10))\n",
    "    \n",
    "    axs[0, 0].set_title(f'패키지상품 미선택한\\n {x} 특성 분포도',fontsize=12,fontweight='bold')\n",
    "    sns.histplot(data[(data[target] == 0)][x],ax=axs[0,0],color='teal')\n",
    "    \n",
    "    axs[0, 1].set_title(f\"패키지상품 선택한\\n {x}특성 분포도\",fontsize=12,fontweight='bold')\n",
    "    sns.histplot(data[(data[target] == 1)][x],ax=axs[0,1],color='orange')\n",
    "    \n",
    "    axs[1,0].set_title(f'패키지상품 선택한 {x} 특성 boxplot',fontsize=12,fontweight='bold')\n",
    "    \n",
    "    line = plt.Line2D((.1,.9),(.5,.5), color='grey', linewidth=1.5,linestyle='--')\n",
    "    fig.add_artist(line)\n",
    "    sns.boxplot(data=data, x=target, y=x, ax=axs[1,0],palette='gist_rainbow',showmeans=True)\n",
    "    \n",
    "    axs[1,1].set_title(f'이상치 제거한 {x} 특성의 boxplot',fontsize=12,fontweight='bold')\n",
    "    sns.boxplot(data=data, x=target, y=x,ax=axs[1,1],showfliers=False,palette='gist_rainbow',showmeans=True) #turning off outliers from boxplot\n",
    "    sns.despine(top=True,right=True,left=True) # to remove side line from graph\n",
    "    \n",
    "    plt.tight_layout(pad=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18665d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all quantitative columns for checking the spread\n",
    "#list_col=  ['Age','DurationOfPitch','MonthlyIncome']\n",
    "\n",
    "list_col=data.select_dtypes(include='number').columns.to_list()\n",
    "\n",
    "#print(list_col)\n",
    "#plt.figure(figsize=(14,23))\n",
    "\n",
    "for j in range(len(list_col)):\n",
    "   plot(list_col[j])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d119999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "['TypeofContact','Occupation','Gender','ProductPitched','MaritalStatus','Designation']\n",
    "\n",
    "# seaborn setting\n",
    "\n",
    "rcParams['figure.figsize'] = 15,8\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "plt.rcParams['font.size'] = 15\n",
    "colors = sns.color_palette('pastel')\n",
    "\n",
    "# 패키지 선택한 성 비율\n",
    "yes = data[data.ProdTaken==1]\n",
    "\n",
    "# 패키지 미선택한 성비율 \n",
    "no = data[data.ProdTaken==0]\n",
    "\n",
    "# 한번에 piechart 2개 보여주기\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(20,20)) #ax1,ax2 refer to your two pies\n",
    "# 1,2 denotes 1 row, 2 columns - if you want to stack vertically, it would be 2,1\n",
    "\n",
    "pie_data=yes['TypeofContact'].value_counts()\n",
    "labels=yes['TypeofContact'].value_counts().index\n",
    "\n",
    "explode = []\n",
    "for i in range(len(labels)):\n",
    "    explode.append(0.01)\n",
    "    \n",
    "ax1.pie(pie_data,labels = labels,colors = colors,explode=explode, autopct = '%1.1f%%', textprops={'fontsize': 15}) #plot first pie\n",
    "ax1.set_title('패키지 선택한 고객의 제품인지방법 비율',fontsize=30)\n",
    "\n",
    "\n",
    "pie_data=no['TypeofContact'].value_counts()\n",
    "labels=no['TypeofContact'].value_counts().index\n",
    "\n",
    "explode = []\n",
    "for i in range(len(labels)):\n",
    "    explode.append(0.01)\n",
    "\n",
    "ax2.pie(pie_data,labels = labels,colors = colors,explode=explode, autopct = '%1.1f%%', textprops={'fontsize': 15}) #plot second pie\n",
    "ax2.set_title('패키지 미선택한 고객의 제품인지방법 비율',fontsize=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95590a42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=data,x='ProdTaken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6efbe6c",
   "metadata": {},
   "source": [
    "### 가설1 : 결혼 후, 여행을 계획중인 아이들이 있으면 가족패키지에 대한 수요가 있어 여행상품신청확률이 높을 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d6fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결혼한 경우의 데이터를 추린다.\n",
    "condition=data[(data.MaritalStatus=='Married')] #| (data.MaritalStatus=='Divorced')]\n",
    "condition['MaritalStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725c6b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 함께 여행을 계획 중인 5세 미만의 어린이 수가 있는 경우의 조건을 추가한다.\n",
    "data_travel_children = condition[condition['NumberOfChildrenVisiting']>0]\n",
    "\n",
    "# 타겟의 imbalance 확인\n",
    "%matplotlib inline\n",
    "\n",
    "sns.countplot(x=data_travel_children['ProdTaken']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ecc1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 타겟 구성비율확인\n",
    "print(data_travel_children['ProdTaken'].value_counts())\n",
    "print(data_travel_children['ProdTaken'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d44a63",
   "metadata": {},
   "source": [
    "해당가설의 최빈값은 당초 원데이터의 최빈값 정확도보다 0.5% 높아지는 것을 보이며, 이는 결혼 후, 여행에 계획중인 아이들이 여행상품선택과는 무관함을 보여준다.  \n",
    "(결혼을 하고 애가 있는 경우(이혼한 경우도) 진행했으나 married와 비슷한 수치를 보였다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18977ee",
   "metadata": {},
   "source": [
    "### 가설2 : 영업 사원의 프레젠테이션 만족도는 가족패키지에 대한 수요와 연관성이 높을 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57fbd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결혼한 경우의 데이터를 추린다.\n",
    "condition=data[(data.MaritalStatus=='Married')] #| (data.MaritalStatus=='Divorced')]\n",
    "condition['MaritalStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e9fc2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 가설2에 따른 영업사원의 프레젠테이션만족도는 가족패키지에 대한 수요를 높일 것이다로 했을 시, 최빈값보다 0.03이 오른 것을 확인할 수 있다.\n",
    "\n",
    "condition2 = data[data['PitchSatisfactionScore']>=3]\n",
    "condition2[condition2['NumberOfChildrenVisiting']>0]['ProdTaken'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccdd26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 타겟의 imbalance 확인\n",
    "%matplotlib inline\n",
    "\n",
    "sns.countplot(x=data_travel_children['ProdTaken']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf50923",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 패키지여행상품선택여부와 소득의 관계표현\n",
    "sns.boxplot(data=data, x=\"ProdTaken\", y=\"MonthlyIncome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f14b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn setting\n",
    "\n",
    "rcParams['figure.figsize'] = 15,8\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "plt.rcParams['font.size'] = 15\n",
    "colors = sns.color_palette('pastel')\n",
    "\n",
    "# 패키지 선택한 성 비율\n",
    "yes = data[data.ProdTaken==1]\n",
    "\n",
    "# 패키지 미선택한 성비율 \n",
    "no = data[data.ProdTaken==0]\n",
    "\n",
    "# 한번에 piechart 2개 보여주기\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(20,20)) #ax1,ax2 refer to your two pies\n",
    "# 1,2 denotes 1 row, 2 columns - if you want to stack vertically, it would be 2,1\n",
    "\n",
    "pie_data=yes['TypeofContact'].value_counts()\n",
    "labels=yes['TypeofContact'].value_counts().index\n",
    "\n",
    "explode = []\n",
    "for i in range(len(labels)):\n",
    "    explode.append(0.01)\n",
    "    \n",
    "ax1.pie(pie_data,labels = labels,colors = colors,explode=explode, autopct = '%1.1f%%', textprops={'fontsize': 15}) #plot first pie\n",
    "ax1.set_title('패키지 선택한 고객의 상품인지방법 비율',fontsize=30)\n",
    "\n",
    "\n",
    "pie_data=no['TypeofContact'].value_counts()\n",
    "labels=no['TypeofContact'].value_counts().index\n",
    "\n",
    "explode = []\n",
    "for i in range(len(labels)):\n",
    "    explode.append(0.01)\n",
    "\n",
    "ax2.pie(pie_data,labels = labels,colors = colors,explode=explode, autopct = '%1.1f%%', textprops={'fontsize': 15}) #plot second pie\n",
    "ax2.set_title('패키지 미선택한 고객의 상품인지방법 비율',fontsize=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한번에 piechart 2개 보여주기\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(20,20)) #ax1,ax2 refer to your two pies\n",
    "# 1,2 denotes 1 row, 2 columns - if you want to stack vertically, it would be 2,1\n",
    "\n",
    "pie_data=yes['MaritalStatus'].value_counts()\n",
    "labels=yes['MaritalStatus'].value_counts().index\n",
    "\n",
    "explode = []\n",
    "for i in range(len(labels)):\n",
    "    explode.append(0.01)\n",
    "    \n",
    "ax1.pie(pie_data,labels = labels,colors = colors,explode=explode,autopct = '%1.1f%%', textprops={'fontsize': 15}) #plot first pie\n",
    "ax1.set_title('패키지 선택한 결혼여부 비율',fontsize=30)\n",
    "\n",
    "\n",
    "pie_data=no['MaritalStatus'].value_counts()\n",
    "labels=no['MaritalStatus'].value_counts().index\n",
    "ax2.pie(pie_data,labels = labels,colors = colors,explode=explode,autopct = '%1.1f%%', textprops={'fontsize': 15}) #plot second pie\n",
    "ax2.set_title('패키지 미선택한 결혼여부 비율',fontsize=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결혼상태별 영업사원판매상품과 비율\n",
    "sns.countplot(x=\"ProductPitched\", data=yes,  hue=\"MaritalStatus\")\n",
    "sns.despine(top=True,right=True,left=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e5cf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 한번에 piechart 2개 보여주기\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(20,20)) #ax1,ax2 refer to your two pies\n",
    "# 1,2 denotes 1 row, 2 columns - if you want to stack vertically, it would be 2,1\n",
    "\n",
    "pie_data=yes['Designation'].value_counts()\n",
    "labels=yes['Designation'].value_counts().index\n",
    "\n",
    "explode = []\n",
    "for i in range(len(labels)):\n",
    "    explode.append(0.01)\n",
    "    \n",
    "ax1.pie(pie_data,labels = labels,colors = colors,explode=explode,autopct = '%1.1f%%', textprops={'fontsize': 15}) #plot first pie\n",
    "ax1.set_title('패키지 선택한 직급 비율',fontsize=30)\n",
    "\n",
    "\n",
    "pie_data=no['Designation'].value_counts()\n",
    "labels=no['Designation'].value_counts().index\n",
    "ax2.pie(pie_data,labels = labels,colors = colors,explode=explode,autopct = '%1.1f%%', textprops={'fontsize': 15}) #plot second pie\n",
    "ax2.set_title('패키지 미선택한 직급 비율',fontsize=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded381c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 직급 영업사원판매상품과 비율\n",
    "sns.countplot(x=\"ProductPitched\", data=yes,  hue=\"Designation\")\n",
    "sns.despine(top=True,right=True,left=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d76131",
   "metadata": {},
   "source": [
    "직함에 매니저라고 적어도 직업에 작은 사업, 큰 사업으로 기재된 경우가 많아, 직함은 큰 의미가 없는 것으로 파악하기로 한다.\n",
    "(기업의 규모마다 매니저의 역할/역량이 다른 경우도 많으니 큰 의미를 두지 않기로 하며, 매니저 이상의 고객군으로 파악하기로 한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0134433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매니저 직함의 직업 종류 분포\n",
    "designation_manager = data[data['Designation']=='Manager']\n",
    "designation_manager['Occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ff90d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 경영진 직함의 직업 종류 분포\n",
    "designation_executive = data[data['Designation']=='Executive']\n",
    "designation_executive['Occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b81cdc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 나이대 분포도\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.countplot(x=data['Age']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db66380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high cardinality 및 특성생성하고 난 후 베이스된 특성 제거\n",
    "data = data.drop(['id','Age','MonthlyIncome','DurationOfPitch'],axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7759bb42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea2635f",
   "metadata": {},
   "source": [
    "## 6. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c3a0ad",
   "metadata": {},
   "source": [
    "### 모델의 유용성과 한계\n",
    "\n",
    "* 목적 : 주어진 특성을 분석하여 패키지 여행을 신청할 지, 말 지 예측\n",
    "* 유용성 : 잠재고객을 파악하여 영업/광고방향 설정 가능\n",
    "* 한계 : \n",
    "* 모델링에 사용할 데이터는 아래의 4가지 종류로 각 모델링에 적용하였다.\n",
    "    1. 전처리한 data  \n",
    "    2. id값만 없앤 raw_data  \n",
    "    3. EDA로 생성한 컬럼/데이터를 카테고리화하여 수치형으로 변경한 data\n",
    "    4. id컬럼만 없앤 raw_data null값에 최빈값으로 대체하고, 수치 data를 없애고 카테고리화하여 수치형으로 변경한 data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cbd7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA로 구간별로 구분한 컬럼을 카테고리화하기\n",
    "category_columns=['Ages','MonthlyIncomeSection','DurationOfPitchSection']\n",
    "numerical_columns=['MonthlyIncome','Age','DurationOfPitch']\n",
    "\n",
    "data[category_columns] = data[category_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cd0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 전처리한 data 훈련/검증셋 나누기\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=2)\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=2)\n",
    "\n",
    "target = 'ProdTaken'\n",
    "features = data.columns.drop([target])\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "X_test = test[features]\n",
    "y_test = test[target]\n",
    "\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c79ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. id컬럼만 없앤 raw_data 훈련/검증셋 나누기\n",
    "\n",
    "train2, test2 = train_test_split(raw_data, test_size=0.2, random_state=2)\n",
    "train2, val2 = train_test_split(train2, test_size=0.2, random_state=2)\n",
    "\n",
    "\n",
    "target = 'ProdTaken'\n",
    "features = raw_data.columns.drop([target])\n",
    "\n",
    "X_train2 = train2[features]\n",
    "y_train2 = train2[target]\n",
    "X_val2 = val2[features]\n",
    "y_val2 = val2[target]\n",
    "X_test2 = test2[features]\n",
    "y_test2 = test2[target]\n",
    "\n",
    "train2.shape, val2.shape, test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. EDA한 DATA의 수치데이터 없애고 카테고리화한 데이터로 훈련검증데이터셋 만들기\n",
    "\n",
    "category_columns=['Ages','MonthlyIncomeSection','DurationOfPitchSection']\n",
    "numerical_columns=['MonthlyIncome','Age','DurationOfPitch']\n",
    "\n",
    "data[category_columns] = data[category_columns].astype('category')\n",
    "\n",
    "# 카테고리화한 데이터를 수치형으로 변경하기\n",
    "category_data=pd.get_dummies(data,drop_first=True)\n",
    "\n",
    "# 훈련/검증셋 나누기\n",
    "\n",
    "train_dumm, test_dumm = train_test_split(category_data, test_size=0.2, random_state=2)\n",
    "train_dumm, val_dumm = train_test_split(train_dumm, test_size=0.2, random_state=2)\n",
    "\n",
    "target = 'ProdTaken'\n",
    "features = category_data.columns.drop([target])\n",
    "\n",
    "X_train_dumm = train_dumm[features]\n",
    "y_train_dumm = train_dumm[target]\n",
    "X_val_dumm = val_dumm[features]\n",
    "y_val_dumm = val_dumm[target]\n",
    "X_test_dumm = test_dumm[features]\n",
    "y_test_dumm = test_dumm[target]\n",
    "\n",
    "train_dumm.shape, val_dumm.shape, test_dumm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03165327",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4. raw_data에 수치형데이터 제거하고 수치형으로 변경(_get_dummies 말고 pd.factorize)후 category타입으로 변경하고 ordinal encoderㅅ\n",
    "\n",
    "\n",
    "imputer=SimpleImputer(strategy='most_frequent')\n",
    "result = imputer.fit_transform(raw_data)\n",
    "imputed_df = pd.DataFrame(result, columns=raw_data.columns)\n",
    "\n",
    "category_raw_data = imputed_df.drop(['MonthlyIncome','Age','DurationOfPitch'],axis=1)\n",
    "category_raw_data \n",
    "\n",
    "category_data_ff = category_raw_data.apply(lambda x: pd.factorize(x)[0])\n",
    "category_data_ff = category_raw_data.astype('category')\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "category_data_ff_encoded = encoder.fit_transform(category_data_ff)\n",
    "\n",
    "train_ff_encoded, test_ff_encoded = train_test_split(category_data_ff_encoded, test_size=0.2, random_state=2)\n",
    "train_ff_encoded, val_ff_encoded = train_test_split(train_ff_encoded, test_size=0.2, random_state=2)\n",
    "\n",
    "target = 'ProdTaken'\n",
    "features = category_data_ff_encoded.columns.drop([target])\n",
    "\n",
    "X_train_ff_encoded = train_ff_encoded[features]\n",
    "y_train_ff_encoded = train_ff_encoded[target]\n",
    "X_val_ff_encoded = val_ff_encoded[features]\n",
    "y_val_ff_encoded = val_ff_encoded[target]\n",
    "X_test_ff_encoded = test_ff_encoded[features]\n",
    "y_test_ff_encoded = test_ff_encoded[target]\n",
    "\n",
    "train_ff_encoded.shape, val_ff_encoded.shape, test_ff_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2af2987",
   "metadata": {},
   "source": [
    "### 1-1. Logistic Regression (AUC:0.77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd21db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# logisticregression, ordinalencoder\n",
    "\n",
    "pipe_log_o = make_pipeline(\n",
    "    OrdinalEncoder(), # 범주형 자료를 모델링할 때는 원핫보다 오디널이 좋음! 중요한 노드가 상위에서 선택되어야하는데 원핫을하면 적용이 잘 안됨! 한가지 특성이 여러가지로 나눠지기 때문에! 그래서 노미널인코딩이라도 오디널을 사용함! 트리에서는 순서ㅁ가 상관없어서 괜찮다!\n",
    "    LogisticRegression(class_weight=\"balanced\"))\n",
    "\n",
    "pipe_log_o.fit(X_train, y_train)\n",
    "y_pred = pipe_log_o.predict(X_val)\n",
    "\n",
    "print('훈련 정확도 :', pipe_log_o.score(X_train,y_train))\n",
    "print('검증 정확도 :', pipe_log_o.score(X_val, y_val))\n",
    "print('F1 score :', f1_score(y_val, y_pred))\n",
    "print('AUC 점수 :', roc_auc_score(y_val, y_pred))\n",
    "print('REPORT',classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55592b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(pipe_log_o,X_val,y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2cf484",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 14\n",
    "tn = 200\n",
    "fn = 42\n",
    "fp = 8\n",
    "total = tp+tn+fp+fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e55f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1로 예측할 확률\n",
    "y_train.value_counts(normalize=True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07ae5af",
   "metadata": {},
   "source": [
    "### 1-2. Logistic Regression(null->most_frequent)  (AUC:0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc88290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logisticregression, ordinalencoder\n",
    "\n",
    "pipe_log_o2 = make_pipeline(\n",
    "    OrdinalEncoder(), # 범주형 자료를 모델링할 때는 원핫보다 오디널이 좋음! 중요한 노드가 상위에서 선택되어야하는데 원핫을하면 적용이 잘 안됨! 한가지 특성이 여러가지로 나눠지기 때문에! 그래서 노미널인코딩이라도 오디널을 사용함! 트리에서는 순서ㅁ가 상관없어서 괜찮다!\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    LogisticRegression(class_weight=\"balanced\",max_iter=1000))\n",
    "\n",
    "pipe_log_o2.fit(X_train2, y_train2)\n",
    "y_pred = pipe_log_o2.predict(X_val2)\n",
    "\n",
    "print('훈련 정확도 :', pipe_log_o2.score(X_train2,y_train2))\n",
    "print('검증 정확도 :', pipe_log_o2.score(X_val2, y_val2))\n",
    "print('F1 score :', f1_score(y_val2, y_pred))\n",
    "print('AUC 점수 :', roc_auc_score(y_val2, y_pred))\n",
    "print('REPORT',classification_report(y_val2, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa8ef87",
   "metadata": {},
   "source": [
    "### 1-3. Logistic Regression Hyper Parameter Tuning (null->most_frequent) (AUC:0.73)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51690fc3",
   "metadata": {},
   "source": [
    "로지스틱회귀에는 실제로 조정할 중요한 파라미터가 없고, 때로는 다른 solver를 사용하여 성능이나 수렴에서 유용한 차이를 볼 수 있다.  \n",
    "정규화(패널티)가 때때로 도움이 될 수 있다.  \n",
    "cf. 모든 solver가 모든 정규화를 지원하지는 않음.  \n",
    "C매개변수는 패널티강도를 제어하며 이또한 효과적일 수 있다.  \n",
    "ex. C in [100, 10, 1.0, 0..1, 0.01]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e670b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic model hyper parameter tuning\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,  scoring='roc_auc',error_score=0)\n",
    "grid_result = grid_search.fit(X_train_dumm, y_train_dumm)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic model에 최적의 hyper parameter 적용\n",
    "\n",
    "# 파라미터설명\n",
    "# C = 정규화강도(값이 작을수록 더 강한 정규화 지정, penalty = 너무 많은 변수를 갖는 로지스틱모델에 벌점부과. 덜 기여하는 변수의 계수가 0으로 축소. 이것이 정규화임.\n",
    "# solver = 최적화 문제에 사용할 알고리즘.클래스의 종류에따라 사용하는 알고리즘이 다름. max_iter = solver의 수렴하는데 최대 반복횟수)\n",
    "\n",
    "log_reg_clf=LogisticRegression(C=0.1, penalty='l2',solver='newton-cg',class_weight='balanced', max_iter=1000)\n",
    "\n",
    "log_reg_clf.fit(X_train_dumm, y_train_dumm)\n",
    "\n",
    "y_pred = log_reg_clf.predict(X_val_dumm)\n",
    "\n",
    "print('훈련 정확도 :', log_reg_clf.score(X_train_dumm,y_train_dumm))\n",
    "print('검증 정확도 :', log_reg_clf.score(X_val_dumm, y_val_dumm))\n",
    "print('F1 score :', f1_score(y_val_dumm, y_pred))\n",
    "print('AUC 점수 :', roc_auc_score(y_val_dumm, y_pred))\n",
    "print('REPORT',classification_report(y_val_dumm, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e29517d",
   "metadata": {},
   "source": [
    "### 1-4 Logistic Regression Hyper Parameter Tuning (null->most_frequent, category화한 data) (AUC:0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14294694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic model에 최적의 hyper parameter 적용\n",
    "\n",
    "# 파라미터설명\n",
    "# C = 정규화강도(값이 작을수록 더 강한 정규화 지정, penalty = 너무 많은 변수를 갖는 로지스틱모델에 벌점부과. 덜 기여하는 변수의 계수가 0으로 축소. 이것이 정규화임.\n",
    "# solver = 최적화 문제에 사용할 알고리즘.클래스의 종류에따라 사용하는 알고리즘이 다름. max_iter = solver의 수렴하는데 최대 반복횟수)\n",
    "\n",
    "log_reg_clf=LogisticRegression(C=0.1, penalty='l2',solver='newton-cg',class_weight='balanced', max_iter=1000)\n",
    "\n",
    "log_reg_clf.fit(X_train_ff_encoded, y_train_ff_encoded)\n",
    "\n",
    "y_pred = log_reg_clf.predict(X_val_ff_encoded)\n",
    "\n",
    "print('훈련 정확도 :', log_reg_clf.score(X_train_ff_encoded,y_train_ff_encoded))\n",
    "print('검증 정확도 :', log_reg_clf.score(X_val_ff_encoded, y_val_ff_encoded))\n",
    "print('F1 score :', f1_score(y_val_ff_encoded, y_pred))\n",
    "print('AUC 점수 :', roc_auc_score(y_val_ff_encoded, y_pred))\n",
    "print('REPORT',classification_report(y_val_ff_encoded, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da09f95f",
   "metadata": {},
   "source": [
    "### 2-1. RandomForest  (AUC:0.70) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5602315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### randomforest_ordinal encoding\n",
    "\n",
    "pipe_rf_o = make_pipeline(\n",
    "    OrdinalEncoder(), # 범주형 자료를 모델링할 때는 원핫보다 오디널이 좋음! 중요한 노드가 상위에서 선택되어야하는데 원핫을하면 적용이 잘 안됨! 한가지 특성이 여러가지로 나눠지기 때문에! 그래서 노미널인코딩이라도 오디널을 사용함! 트리에서는 순서가 상관없어서 괜찮다!\n",
    "    RandomForestClassifier(random_state=2))\n",
    "\n",
    "pipe_rf_o.fit(X_train, y_train)\n",
    "y_pred = pipe_rf_o.predict(X_val)\n",
    "\n",
    "print('훈련 정확도 :', pipe_rf_o.score(X_train,y_train))\n",
    "print('검증 정확도 :', pipe_rf_o.score(X_val, y_val))\n",
    "print('F1 score :', f1_score(y_val, y_pred))\n",
    "print('AUC 점수 :', roc_auc_score(y_val, y_pred))\n",
    "print('REPORT',classification_report(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8207a42d",
   "metadata": {},
   "source": [
    "### 2-2. RandomForest(null->most_frequent)  (AUC:0.74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936f4e72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# randomforest_ordinal encoding\n",
    "\n",
    "pipe_rf_o2 = make_pipeline(\n",
    "    OrdinalEncoder(), # 범주형 자료를 모델링할 때는 원핫보다 오디널이 좋음! 중요한 노드가 상위에서 선택되어야하는데 원핫을하면 적용이 잘 안됨! 한가지 특성이 여러가지로 나눠지기 때문에! 그래서 노미널인코딩이라도 오디널을 사용함! 트리에서는 순서가 상관없어서 괜찮다!\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    RandomForestClassifier(random_state=2))\n",
    "\n",
    "pipe_rf_o2.fit(X_train2, y_train2)\n",
    "y_pred = pipe_rf_o2.predict(X_val2)\n",
    "\n",
    "print('훈련 정확도 :', pipe_rf_o2.score(X_train2,y_train2))\n",
    "print('검증 정확도 :', pipe_rf_o2.score(X_val2, y_val2))\n",
    "print('F1 score :', f1_score(y_val2, y_pred))\n",
    "print('AUC 점수 :', roc_auc_score(y_val2, y_pred))\n",
    "print('REPORT',classification_report(y_val2,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb61c9",
   "metadata": {},
   "source": [
    "### 2-3. RandomForest Hyperparameter Tuning  (AUC:0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c344d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### pipe라인 랜덤포레스트 모델의 파라미터튜닝\n",
    "pipe = make_pipeline(\n",
    "      OrdinalEncoder(),\n",
    "      RandomForestClassifier(random_state=2))\n",
    "\n",
    "# 튜닝할 하이퍼파라미터의 범위를 지정\n",
    "parameters = {'randomforestclassifier__max_depth': range(1, 5, 2), \n",
    "              'randomforestclassifier__max_features': range(1, 5, 2), \n",
    "              'randomforestclassifier__min_samples_leaf' : range(1, 5, 2)}\n",
    "    \n",
    "# 최적의 hyper parameter를 찾기 위한 RandomizedSearchCV\n",
    "rf_classifier = RandomizedSearchCV(pipe, \n",
    "                                    param_distributions=parameters, #  param_distributions : 사전/사전목록\n",
    "                                    n_iter=8, # 정수, 기본값=10인데, parameter만큼으로 8로함.\n",
    "                                    cv=5, # 교차검증생성기 또는 반복가능 default=None\n",
    "                                    scoring='roc_auc', # 평가방법\n",
    "                                    verbose=1) # 진행상황표시. 높을수록 더 많은 메세지표시.\n",
    "rf_classifier.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb3957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomSearchCV 결과 확인\n",
    "print('Best Parameters :', rf_classifier.best_params_)\n",
    "print('검증정확도 :', rf_classifier.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382b7c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomforest_ordinal encoding\n",
    "\n",
    "pipe_rf_o = make_pipeline(\n",
    "    OrdinalEncoder(), # 범주형 자료를 모델링할 때는 원핫보다 오디널이 좋음! 중요한 노드가 상위에서 선택되어야하는데 원핫을하면 적용이 잘 안됨! 한가지 특성이 여러가지로 나눠지기 때문에! 그래서 노미널인코딩이라도 오디널을 사용함! 트리에서는 순서가 상관없어서 괜찮다!\n",
    "    RandomForestClassifier(random_state=2, min_samples_leaf=1, max_features=3, max_depth=3,class_weight=\"balanced\"))\n",
    "\n",
    "pipe_rf_o.fit(X_train, y_train)\n",
    "y_pred = pipe_rf_o.predict(X_val)\n",
    "\n",
    "print('훈련 정확도 :', pipe_rf_o.score(X_train,y_train))\n",
    "print('검증 정확도 :', pipe_rf_o.score(X_val, y_val))\n",
    "print('F1 score :', f1_score(y_val, y_pred,average='weighted'))\n",
    "print('AUC 점수 :', roc_auc_score(y_val, y_pred))\n",
    "print('REPORT',classification_report(y_val,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638efbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(pipe_rf_o,X_val,y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b46c8a6",
   "metadata": {},
   "source": [
    "### 2-4. RandomForest Hyperparameter Tuning (null -> most_frequent)  (AUC:0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a606c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### pipe라인 랜덤포레스트 모델의 파라미터튜닝\n",
    "pipe = make_pipeline(\n",
    "      OrdinalEncoder(),\n",
    "      SimpleImputer(strategy='most_frequent'),\n",
    "      RandomForestClassifier(random_state=2))\n",
    "\n",
    "# 튜닝할 하이퍼파라미터의 범위를 지정\n",
    "parameters = {'randomforestclassifier__max_depth': range(1, 5, 2), \n",
    "              'randomforestclassifier__max_features': range(1, 5, 2), \n",
    "              'randomforestclassifier__min_samples_leaf' : range(1, 5, 2)}\n",
    "    \n",
    "# 최적의 hyper parameter를 찾기 위한 RandomizedSearchCV\n",
    "rf_classifier = RandomizedSearchCV(pipe, \n",
    "                                    param_distributions=parameters, #  param_distributions : 사전/사전목록\n",
    "                                    n_iter=8, # 정수, 기본값=10\n",
    "                                    cv=5, # 교차검증생성기 또는 반복가능 default=None\n",
    "                                    scoring='roc_auc', # 평가방법\n",
    "                                    verbose=1) # 진행상황표시. 높을수록 더 많은 메세지표시.\n",
    "rf_classifier.fit(X_train2, y_train2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomSearchCV 결과 확인\n",
    "print('Best Parameters :', rf_classifier.best_params_)\n",
    "print('검증정확도 :', rf_classifier.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ebe72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# randomforest_ordinal encoding\n",
    "\n",
    "pipe_rf_or = make_pipeline(\n",
    "    OrdinalEncoder(), # 범주형 자료를 모델링할 때는 원핫보다 오디널이 좋음! 중요한 노드가 상위에서 선택되어야하는데 원핫을하면 적용이 잘 안됨! 한가지 특성이 여러가지로 나눠지기 때문에! 그래서 노미널인코딩이라도 오디널을 사용함! 트리에서는 순서가 상관없어서 괜찮다!\n",
    "    SimpleImputer(strategy='most_frequent'),    \n",
    "    RandomForestClassifier(random_state=2, min_samples_leaf=3, max_features=1, max_depth=3,class_weight='balanced'))\n",
    "\n",
    "pipe_rf_or.fit(X_train2, y_train2)\n",
    "y_pred = pipe_rf_or.predict(X_val2)\n",
    "\n",
    "print('훈련 정확도 :', pipe_rf_or.score(X_train2,y_train2))\n",
    "print('검증 정확도 :', pipe_rf_or.score(X_val2, y_val2))\n",
    "print('F1 score :', f1_score(y_val2, y_pred))\n",
    "print('AUC 점수 :', roc_auc_score(y_val2, y_pred))\n",
    "print('REPORT',classification_report(y_val2,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c9f9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(pipe_rf_or,X_val2,y_val2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00175c3e",
   "metadata": {},
   "source": [
    "### 3-1. XGBoost  (AUC:0.73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d61b45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier,XGBRegressor\n",
    "\n",
    "pipe_xgb_o = make_pipeline(\n",
    "    OrdinalEncoder(), # 범주형 자료를 모델링할 때는 원핫보다 오디널이 좋음! 중요한 노드가 상위에서 선택되어야하는데 원핫을하면 적용이 잘 안됨! 한가지 특성이 여러가지로 나눠지기 때문에! 그래서 노미널인코딩이라도 오디널을 사용함! 트리에서는 순서가 상관없어서 괜찮다!\n",
    "    XGBClassifier())\n",
    "\n",
    "pipe_xgb_o.fit(X_train, y_train)\n",
    "y_pred = pipe_xgb_o.predict(X_val)\n",
    "\n",
    "print('훈련 정확도 :', pipe_xgb_o.score(X_train,y_train))\n",
    "print('검증 정확도 :', pipe_xgb_o.score(X_val, y_val))\n",
    "print('F1 score :', f1_score(y_val, y_pred))\n",
    "print('AUC 점수 :', roc_auc_score(y_val, y_pred))\n",
    "print('REPORT',classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9daccb",
   "metadata": {},
   "source": [
    "### 3-2. XGBoost (null->most_frequent)  (AUC:0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e0265",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier,XGBRegressor\n",
    "\n",
    "pipe_xgb_o2 = make_pipeline(\n",
    "    OrdinalEncoder(), # 범주형 자료를 모델링할 때는 원핫보다 오디널이 좋음! 중요한 노드가 상위에서 선택되어야하는데 원핫을하면 적용이 잘 안됨! 한가지 특성이 여러가지로 나눠지기 때문에! 그래서 노미널인코딩이라도 오디널을 사용함! 트리에서는 순서가 상관없어서 괜찮다!\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    XGBClassifier())\n",
    "\n",
    "pipe_xgb_o2.fit(X_train2, y_train2)\n",
    "y_pred = pipe_xgb_o2.predict(X_val2)\n",
    "\n",
    "print('훈련 정확도 :', pipe_xgb_o2.score(X_train2,y_train2))\n",
    "print('검증 정확도 :', pipe_xgb_o2.score(X_val2, y_val2))\n",
    "print('F1 score :', f1_score(y_val2, y_pred))\n",
    "print('AUC 점수 :', roc_auc_score(y_val2, y_pred))\n",
    "print('REPORT',classification_report(y_val2, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db22a89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data['ProdTaken'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio0 = data['ProdTaken'].value_counts(normalize=True)[0]\n",
    "ratio1 = data['ProdTaken'].value_counts(normalize=True)[1]\n",
    "ratio = ratio1/ratio0\n",
    "ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b70cd0",
   "metadata": {},
   "source": [
    "### 3-3. XGBoost Hyperparameter (null -> most_frequent) Tuning (AUC : 0.82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c7c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tuned = XGBClassifier(random_state=25,eval_metric='logloss') # 조기 중단을 위한 평가지표 eval_metric\n",
    "\n",
    "# Grid of parameters to choose \n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\": np.arange(10,100,20),\n",
    "    \"scale_pos_weight\":[0,5],\n",
    "    \"colsample_bylevel\":[0.5,1],\n",
    "    \"learning_rate\":[0.001,0.01,0.1,0.5]\n",
    "}\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = metrics.make_scorer(metrics.roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tuned = XGBClassifier(random_state=25,eval_metric='logloss') # 조기 중단을 위한 평가지표 eval_metric\n",
    "\n",
    "# Grid of parameters to choose \n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\": np.arange(10,100,20),\n",
    "    \"scale_pos_weight\":[0,5],\n",
    "    \"colsample_bylevel\":[0.5,1],\n",
    "    \"learning_rate\":[0.001,0.01,0.1,0.5]\n",
    "}\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = metrics.make_scorer(metrics.roc_auc_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(xgb_tuned, parameters,scoring=acc_scorer,cv=5,n_jobs=-1)\n",
    "grid_obj = grid_obj.fit(X_train_dumm, y_train_dumm,sample_weight=compute_sample_weight(\"balanced\", y_train_dumm))\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "xgb_tuned = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data.->이 코딩과 무관하게 정확도 등 값은 동일하게 나옴.\n",
    "xgb_tuned.fit(X_train_dumm, y_train_dumm,sample_weight=compute_sample_weight(\"balanced\", y_train_dumm))\n",
    "\n",
    "y_pred = xgb_tuned.predict(X_val_dumm)\n",
    "\n",
    "print('훈련 정확도 :', xgb_tuned.score(X_train_dumm,y_train_dumm))\n",
    "print('검증 정확도 :', xgb_tuned.score(X_val_dumm, y_val_dumm))\n",
    "print('F1 score :', f1_score(y_val_dumm, y_pred))\n",
    "print('AUC 점수 :', roc_auc_score(y_val_dumm, y_pred))\n",
    "print('REPORT',classification_report(y_val_dumm,y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68e0493",
   "metadata": {},
   "source": [
    "### 4-1. CatBoost  (AUC:0.72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fec96b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost, ordinalencoder\n",
    "\n",
    "pipe_cat_o = make_pipeline(\n",
    "    OrdinalEncoder(), # 범주형 자료를 모델링할 때는 원핫보다 오디널이 좋음! 중요한 노드가 상위에서 선택되어야하는데 원핫을하면 적용이 잘 안됨! 한가지 특성이 여러가지로 나눠지기 때문에! 그래서 노미널인코딩이라도 오디널을 사용함! 트리에서는 순서가 상관없어서 괜찮다!\n",
    "    CatBoostClassifier(random_state=2))\n",
    "\n",
    "pipe_cat_o.fit(X_train, y_train)\n",
    "y_pred = pipe_cat_o.predict(X_val)\n",
    "\n",
    "print('훈련 정확도 :', pipe_cat_o.score(X_train,y_train))\n",
    "print('검증 정확도 :', pipe_cat_o.score(X_val, y_val))\n",
    "print('F1 score :', f1_score(y_val, y_pred))\n",
    "print('AUC 점수 :', roc_auc_score(y_val, y_pred))\n",
    "print('REPORT',classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a72d9",
   "metadata": {},
   "source": [
    "### 4-2. CatBoost (null->most_frequent)  (AUC:0.73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b651043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost, ordinalencoder\n",
    "\n",
    "pipe_cat_o2 = make_pipeline(\n",
    "    OrdinalEncoder(), # 범주형 자료를 모델링할 때는 원핫보다 오디널이 좋음! 중요한 노드가 상위에서 선택되어야하는데 원핫을하면 적용이 잘 안됨! 한가지 특성이 여러가지로 나눠지기 때문에! 그래서 노미널인코딩이라도 오디널을 사용함! 트리에서는 순서가 상관없어서 괜찮다!\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    CatBoostClassifier(random_state=2))\n",
    "\n",
    "pipe_cat_o2.fit(X_train2, y_train2)\n",
    "y_pred = pipe_cat_o2.predict(X_val2)\n",
    "\n",
    "print('훈련 정확도 :', pipe_cat_o2.score(X_train2,y_train2))\n",
    "print('검증 정확도 :', pipe_cat_o2.score(X_val2, y_val2))\n",
    "print('F1 score :', f1_score(y_val2, y_pred))\n",
    "print('AUC 점수 :', roc_auc_score(y_val2, y_pred))\n",
    "print('REPORT',classification_report(y_val2, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4750e",
   "metadata": {},
   "source": [
    "### 4-3. CatBoost Hyper Parameter (null->most_frequent)  (AUC:0.67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa2c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc=CatBoostClassifier(random_state=2)\n",
    "\n",
    "grid = {'depth': [4,5,6,7,8,9, 10],\n",
    "        'learning_rate' : [0.01,0.02,0.03,0.04],\n",
    "        'iterations'    : [10, 20,30,40,50,60,70,80,90, 100]}\n",
    "\n",
    "gscv = GridSearchCV (estimator = cbc, param_grid = grid, scoring ='roc_auc', cv = 5)\n",
    "\n",
    "gscv.fit(X_train_dumm,y_train_dumm,sample_weight=compute_sample_weight(\"balanced\", y_train_dumm))\n",
    "\n",
    "print(gscv.best_estimator_)\n",
    "print(gscv.best_score_)\n",
    "print(gscv.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007bbc16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# catboost, ordinalencoder\n",
    "\n",
    "pipe_cat_o2_h = make_pipeline(\n",
    "    OrdinalEncoder(), # 범주형 자료를 모델링할 때는 원핫보다 오디널이 좋음! 중요한 노드가 상위에서 선택되어야하는데 원핫을하면 적용이 잘 안됨! 한가지 특성이 여러가지로 나눠지기 때문에! 그래서 노미널인코딩이라도 오디널을 사용함! 트리에서는 순서가 상관없어서 괜찮다!\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    CatBoostClassifier(random_state=2,depth=9,iterations=100,learning_rate=0.04))\n",
    "\n",
    "pipe_cat_o2_h.fit(X_train_dumm, y_train_dumm)\n",
    "y_pred = pipe_cat_o2_h.predict(X_val_dumm)\n",
    "\n",
    "print('훈련 정확도 :', pipe_cat_o2_h.score(X_train_dumm,y_train_dumm))\n",
    "print('검증 정확도 :', pipe_cat_o2_h.score(X_val_dumm, y_val_dumm))\n",
    "print('F1 score :', f1_score(y_val_dumm, y_pred))\n",
    "print('AUC 점수 :', roc_auc_score(y_val_dumm, y_pred))\n",
    "print('REPORT',classification_report(y_val_dumm, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ed5da",
   "metadata": {},
   "source": [
    "### 4-4. CatBoost Hyper Parameter (null->most_frequent)  (AUC:0.72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1fa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### catboost, ordinalencoder\n",
    "\n",
    "pipe_cat_o2_h = make_pipeline(\n",
    "    OrdinalEncoder(), # 범주형 자료를 모델링할 때는 원핫보다 오디널이 좋음! 중요한 노드가 상위에서 선택되어야하는데 원핫을하면 적용이 잘 안됨! 한가지 특성이 여러가지로 나눠지기 때문에! 그래서 노미널인코딩이라도 오디널을 사용함! 트리에서는 순서가 상관없어서 괜찮다!\n",
    "    CatBoostClassifier(random_state=2,loss_function='MultiClass',depth=10,iterations=100,learning_rate=0.04))\n",
    "\n",
    "pipe_cat_o2_h.fit(X_train2, y_train2)\n",
    "y_pred = pipe_cat_o2_h.predict(X_val2)\n",
    "\n",
    "print('훈련 정확도 :', pipe_cat_o2_h.score(X_train2,y_train2))\n",
    "print('검증 정확도 :', pipe_cat_o2_h.score(X_val2, y_val2))\n",
    "print('F1 score :', f1_score(y_val2, y_pred))\n",
    "print('AUC 점수 :', roc_auc_score(y_val2, y_pred))\n",
    "print('REPORT',classification_report(y_val2, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d7980",
   "metadata": {},
   "source": [
    "### 최종 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b76373",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tuned = XGBClassifier(random_state=25,eval_metric='logloss') # 조기 중단을 위한 평가지표 eval_metric\n",
    "\n",
    "# Grid of parameters to choose \n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\": np.arange(10,100,20),\n",
    "    \"scale_pos_weight\":[0,5],\n",
    "    \"colsample_bylevel\":[0.5,1],\n",
    "    \"learning_rate\":[0.001,0.01,0.1,0.5]}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = metrics.make_scorer(metrics.roc_auc_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(xgb_tuned, parameters,scoring=acc_scorer,cv=5,n_jobs=-1)\n",
    "grid_obj = grid_obj.fit(X_train_dumm, y_train_dumm,sample_weight=compute_sample_weight(\"balanced\", y_train_dumm))\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "xgb_tuned = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data.->이 코딩과 무관하게 정확도 등 값은 동일하게 나옴.\n",
    "xgb_tuned.fit(X_train_dumm, y_train_dumm,sample_weight=compute_sample_weight(\"balanced\", y_train_dumm))\n",
    "\n",
    "y_pred = xgb_tuned.predict(X_val_dumm)\n",
    "\n",
    "print('훈련 정확도 :', xgb_tuned.score(X_train_dumm,y_train_dumm))\n",
    "print('검증 정확도 :', xgb_tuned.score(X_val_dumm, y_val_dumm))\n",
    "print('F1 score :', f1_score(y_val_dumm, y_pred))\n",
    "print('AUC 점수 :', roc_auc_score(y_val_dumm, y_pred))\n",
    "print('REPORT',classification_report(y_val_dumm,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_curve(타겟값, prob of 1)\n",
    "\n",
    "model = xgb_tuned\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_val_dumm)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_val_dumm, y_pred_proba)\n",
    "\n",
    "roc = pd.DataFrame({\n",
    "    'FPR(Fall-out)': fpr, \n",
    "    'TPRate(Recall)': tpr, \n",
    "    'Threshold': thresholds\n",
    "})\n",
    "# print(roc)\n",
    "\n",
    "# roc 시각화\n",
    "plt.rcParams[\"figure.figsize\"] = (10,4)\n",
    "plt.subplot(121)\n",
    "plt.scatter(fpr, tpr)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('FPR(Fall-out)')\n",
    "plt.ylabel('TPR(Recall)');\n",
    "\n",
    "# threshold 최대값의 인덱스, np.argmax()\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print('idx:', optimal_idx, ', threshold:', optimal_threshold)\n",
    "\n",
    "# auc 시각화\n",
    "plt.subplot(122)\n",
    "plt.plot(tpr-fpr);\n",
    "\n",
    "# threshold 설정 및 레포트\n",
    "y_pred_optimal = y_pred_proba >= optimal_threshold\n",
    "print('Report \\n',classification_report(y_val_dumm, y_pred_optimal))\n",
    "\n",
    "# auc 점수\n",
    "auc_score = roc_auc_score(y_val_dumm, y_pred_optimal)\n",
    "print('최종 검증 정확도: ', accuracy_score(y_val_dumm, y_pred_optimal))\n",
    "print('최종 f1 스코어',f1_score(y_val_dumm, y_pred_optimal))\n",
    "print('최종 auc점수 : ', auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a97b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터 성능확인\n",
    "model = xgb_tuned\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test_dumm)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test_dumm, y_pred_proba)\n",
    "\n",
    "roc = pd.DataFrame({\n",
    "    'FPR(Fall-out)': fpr, \n",
    "    'TPRate(Recall)': tpr, \n",
    "    'Threshold': thresholds\n",
    "})\n",
    "# print(roc)\n",
    "\n",
    "# roc 시각화\n",
    "plt.rcParams[\"figure.figsize\"] = (10,4)\n",
    "plt.subplot(121)\n",
    "plt.scatter(fpr, tpr)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('FPR(Fall-out)')\n",
    "plt.ylabel('TPR(Recall)');\n",
    "\n",
    "# threshold 최대값의 인덱스, np.argmax()\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print('idx:', optimal_idx, ', threshold:', optimal_threshold)\n",
    "\n",
    "# auc 시각화\n",
    "plt.subplot(122)\n",
    "plt.plot(tpr-fpr);\n",
    "\n",
    "# threshold 설정 및 레포트\n",
    "y_pred_optimal = y_pred_proba >= optimal_threshold\n",
    "print('Report \\n',classification_report(y_test_dumm, y_pred_optimal))\n",
    "\n",
    "# auc 점수\n",
    "auc_score = roc_auc_score(y_test_dumm, y_pred_optimal)\n",
    "print('최종 검증 정확도: ', accuracy_score(y_test_dumm, y_pred_optimal))\n",
    "print('최종 f1 스코어',f1_score(y_test_dumm, y_pred_optimal))\n",
    "print('최종 auc점수 : ', auc_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d63f870",
   "metadata": {},
   "source": [
    "# 머신러닝모델해석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769fb83",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e21856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. EDA한 DATA의 수치데이터 없애고 카테고리화한 데이터로 훈련검증데이터셋 만들기-> 재실행\n",
    "\n",
    "category_columns=['Ages','MonthlyIncomeSection','DurationOfPitchSection']\n",
    "numerical_columns=['MonthlyIncome','Age','DurationOfPitch']\n",
    "\n",
    "data[category_columns] = data[category_columns].astype('category')\n",
    "\n",
    "# 카테고리화한 데이터를 수치형으로 변경하기\n",
    "category_data=pd.get_dummies(data,drop_first=True)\n",
    "\n",
    "# 훈련/검증셋 나누기\n",
    "\n",
    "train_dumm, test_dumm = train_test_split(category_data, test_size=0.2, random_state=2)\n",
    "train_dumm, val_dumm = train_test_split(train_dumm, test_size=0.2, random_state=2)\n",
    "\n",
    "target = 'ProdTaken'\n",
    "features = category_data.columns.drop([target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c0dc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dumm_=train_dumm[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb2b107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances = pd.Series(model.feature_importances_, train_dumm_.columns)\n",
    "plt.figure(figsize=(10,10))\n",
    "importances.sort_values().plot.barh();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ad84e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_category_data=['CityTier', 'NumberOfPersonVisiting', 'NumberOfFollowups',\n",
    "       'PreferredPropertyStar', 'NumberOfTrips', 'Passport',\n",
    "       'PitchSatisfactionScore', 'OwnCar', 'NumberOfChildrenVisiting',\n",
    "       'TypeofContact_Self Enquiry', 'Occupation_Large Business',\n",
    "       'Occupation_Salaried', 'Occupation_Small Business', 'Gender_Male',\n",
    "       'ProductPitched_Deluxe', 'ProductPitched_King',\n",
    "       'ProductPitched_Standard', 'ProductPitched_Super Deluxe',\n",
    "       'MaritalStatus_Married', 'MaritalStatus_Single',\n",
    "       'MaritalStatus_Unmarried', 'Designation_Executive',\n",
    "       'Designation_Manager', 'Designation_Senior Manager', 'Designation_VP',\n",
    "       'Ages_20', 'Ages_30', 'Ages_40', 'Ages_50', 'Ages_60',\n",
    "       'DurationOfPitchSection_~10', 'DurationOfPitchSection_~15',\n",
    "       'DurationOfPitchSection_~20', 'DurationOfPitchSection_~25',\n",
    "       'DurationOfPitchSection_~30', 'DurationOfPitchSection_~35',\n",
    "       'DurationOfPitchSection_~40', 'MonthlyIncomeSection_~20000',\n",
    "       'MonthlyIncomeSection_~25000', 'MonthlyIncomeSection_~30000',\n",
    "       'MonthlyIncomeSection_~35000', 'MonthlyIncomeSection_~40000',\n",
    "       'MonthlyIncomeSection_~45000', 'MonthlyIncomeSection_~50000',\n",
    "       'MonthlyIncomeSection_~100000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 144\n",
    "\n",
    "for i in new_category_data:\n",
    "    feature = i\n",
    "    isolated = pdp_isolate(\n",
    "        model=model, \n",
    "        dataset=train_dumm_, \n",
    "        model_features=train_dumm_.columns, \n",
    "        feature=feature,\n",
    "        grid_type='percentile', # default='percentile', or 'equal'\n",
    "        num_grid_points=10 # default=10\n",
    "    )\n",
    "    pdp_plot(isolated, feature_name=feature);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e005cb61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(train_dumm_.iloc[:100])\n",
    "shap.force_plot(explainer.expected_value, shap_values, train_dumm_.iloc[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbffbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(train_dumm_.iloc[:300])\n",
    "shap.summary_plot(shap_values, train_dumm_.iloc[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79397d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, train_dumm_.iloc[:300], plot_type=\"violin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d60fbc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, train_dumm_.iloc[:300], plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2478d7",
   "metadata": {},
   "source": [
    "### 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08f258",
   "metadata": {},
   "source": [
    "데이터가 다음 아래의 내용이 없어 분석하는데 아쉬운 부분이 있었다.\n",
    "1. 어떤 사람 대상인지, \n",
    "2. 수집된 시점은 언제인지(코로나 전/후), \n",
    "3. 어디서 수집 됐는지(어느 지역(나라), \n",
    "4. 고객이 만족도를 어떻게 표시한 부분인지,\n",
    "5. 데이터의 단위누락(소득이 개인인지, 가정인지, 프레젠테이션 기간의 단위는 일인건지)\n",
    "6. 고객이 선택한 여행을 위해 지출한 비용\n",
    "\n",
    "하지만 모든 데이터가 완벽할 수 없는 것처럼 우리가 확보한 가장 좋은 것은 VIP에 대한 정보이다.  \n",
    "각 그래프 확인 결과 당초 특성의 연관분석에 대해 시각화한 것과 마찬가지로 PassPort가 가장 상위에서 연관성이 있음을 확인할 수 있다.  \n",
    "현재 사용가능한 데이터를 사용한 것이 1955개의 데이터만 사용했음에도 고객이 여행상품을 선택할지에 대한 괜찮은 성능의 Modeling을 했다.  \n",
    "\n",
    "현재 다뤄본 데이터는 일반적인 여행사가 고객의 소득자료까지는 알 수 없으니 고소득자의 금융권 데이터와 여행사의 합성데이터라고 간주하였다.  \n",
    "또한 우리나라의 경우 해당 소득군에 있는 사람들은 해외여행을 즐기기에 여권이 있는 경우가 많다고 보아, 여권이 필요없고 고소득자가 많은 곳은 미국으로 간주하였다.   \n",
    "회사에서 해당 VIP의 고객유치를 확충하기 위해서는 여행을 스스로 알아볼 수 있도록 SNS 바이럴마케팅을 이용하는 것이 효과적일 것으로 보인다.\n",
    "나이대별로 아이와 같이 지내기 좋은 basic한 등급을 여름휴가, 겨울휴가에 맞춰 바이럴마케팅을 하여 패키지여행을 할 수 있도록 광고해야하는데, 고객군 대부분이 남자인 것을 볼 때, 육아에 지친 엄마를 위해서 아빠가 어떤 특징을 고려하는지 부각시킨다면 효과적으로 보일 것이라 기대한다.  \n",
    "\n",
    "프레젠테이션 이후 이뤄진 조치의 만족도 또한 고객이 선택하는데 중요한 요소이기에 높이기 위해서는 회사에서 영업사원을 위한 교육이 필요할 것으로 보인다.   \n",
    "만족도를 높이기 위해 어떤 식으로 말해야하는지 교육을 하며, 주력상품을 홍보하기 위해 리플렛, 홈페이지는 어떤 식으로 관리되고 있는지 확인하고,  \n",
    "홈페이지에서는 가능한한 어렵지 않게 고객이 여행상품을 구입할 수 있도록 ux-ui를 관리하는 것이 필요할 것으로 보인다.\n",
    "\n",
    "위의 분석을 바탕으로 여행사에서 갖고있는 추가적인 내부 데이터를 활용하여  \n",
    "여행사입장에서는 고객에게 맞춤형서비스를 제공하며, 소비자는 추가적인 조사 없이 여행상품을 선택한다면,  \n",
    "여행사는 광고비용을, 소비자는 시간을 절감하는 데이터분석이 가능할 것으로 기대한다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kerneljookjima",
   "language": "python",
   "name": "kerneljookjima"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
